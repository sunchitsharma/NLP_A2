{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing corpus and reading it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL DATASET \n",
    "\n",
    "from nltk.corpus import brown\n",
    "train_lab = brown.tagged_sents()[0:len(brown.tagged_sents())*80/100]\n",
    "# test_lab = brown.tagged_sents()[len(brown.tagged_sents())*2/10+1:len(brown.tagged_sents())]\n",
    "# train = brown.sents()[0:len(brown.sents())*8/10]\n",
    "# test = brown.sents()[len(brown.sents())*8/10+1:len(brown.sents())]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((u'FW-AT',), 19), ((u'RP-NC',), 5), ((u'BER*-NC',), 1), ((u'WPS+BEZ-TL',), 1), ((u'FW-NR-TL',), 2), ((u'JJ-TL-NC',), 1), ((u'BER-NC',), 5), ((u'AT-HL',), 330), ((u'TO-TL',), 10), ((u'DT-TL',), 8), ((u'EX',), 1827), ((u'DO*',), 289), ((u'BER-HL',), 11), ((u'NN$',), 1221), ((u'PPSS',), 9767), ((u'RB',), 29305), ((u'NP+HVZ-NC',), 1), ((u'WRB-NC',), 7), ((u'VBG+TO',), 4), ((u'MD-HL',), 27), ((u'DT+BEZ',), 97), ((u'NN$-TL',), 328), ((u'EX+HVZ',), 1), ((u'WPS-TL',), 11), ((u'IN-NC',), 41), ((u'VB+JJ-NC',), 1), ((u'JJ$-TL',), 1), ((u'FW-VB',), 17), ((u'FW-NN-NC',), 5), ((u'FW-*-TL',), 2), ((u'WRB+BEZ',), 7), ((u'MD*',), 555), ((u'WRB+DOD',), 2), ((u'VBN-TL-HL',), 6), ((u'QL-NC',), 2), ((u'AP+AP-NC',), 1), ((u'FW-JJ-TL',), 72), ((u'NP$-TL',), 124), ((u'NP',), 29359), ((u'PPL-HL',), 1), ((u'CC-TL',), 293), ((u'WPS',), 3429), ((u'TO-NC',), 13), ((u'QL',), 7535), ((u'PPO',), 7478), ((u'RBT',), 88), ((u'JJR-NC',), 5), ((u'FW-OD-TL',), 3), ((u'VBZ-HL',), 72), ((u'NPS-TL',), 64), ((u'PPSS+BER',), 140), ((u'FW-NPS',), 2), ((u'WPO-NC',), 1), ((u'PPSS+HV',), 128), ((u'BEZ-HL',), 30), ((u'MD',), 10725), ((u'NNS-TL-HL',), 14), ((u'RP',), 4265), ((u'NP-TL-HL',), 7), ((u'ABL',), 313), ((u'BEG',), 593), ((u'---HL',), 26), ((u'NR-HL',), 10), ((u'MD+TO',), 1), ((u'HVD',), 3326), ((u'FW-PN',), 1), ((u'FW-PPL+VBZ',), 2), ((u'RB-NC',), 24), ((u'VBD',), 17905), ((u',',), 48314), ((u'WDT',), 4782), ((u'FW-VB-NC',), 2), ((u'NPS$-HL',), 1), ((u'VBG-TL',), 126), ((u'NP-HL',), 514), ((u'NNS$-HL',), 4), ((u'RP-HL',), 14), ((u'JJR',), 1725), ((u'BEDZ',), 7325), ((u'IN-TL',), 1427), ((u'DOZ-HL',), 16), ((u'DT-HL',), 5), ((u'FW-WDT',), 15), ((u'FW-VBN',), 11), ((u'EX-NC',), 1), ((u'JJ-NC',), 39), ((u'PPS+HVD',), 25), ((u'BER',), 4169), ((u'PPSS+MD-NC',), 2), ((u'DTS',), 2217), ((u'WPS+MD',), 5), ((u'NPS-NC',), 2), ((u'FW-CC',), 25), ((u'NN+IN',), 1), ((u'BER-TL',), 6), ((u'HVZ-NC',), 2), ((u'QL-HL',), 4), ((u'DOZ*',), 62), ((u'DTS-HL',), 2), ((u'EX+HVD',), 1)]\n"
     ]
    }
   ],
   "source": [
    "from itertools import tee, izip\n",
    "\n",
    "transition_tri={}\n",
    "transition_bi={}\n",
    "context={}\n",
    "emission={}\n",
    "\n",
    "def window(iterable, size):\n",
    "    iters = tee(iterable, size)\n",
    "    for i in xrange(1, size):\n",
    "        for each in iters[i:]:\n",
    "            next(each, None)\n",
    "    return izip(*iters)\n",
    "\n",
    "\n",
    "# MAKING DICT {(TAG,TAG,TAG) : COUNT}\n",
    "           \n",
    "\n",
    "for i in train_lab:\n",
    "    for each in window(i,3):\n",
    "        temp=list(each)\n",
    "        temp2=[]\n",
    "        temp2.append(temp[0][1])\n",
    "        temp2.append(temp[1][1])\n",
    "        temp2.append(temp[2][1])\n",
    "        temp=temp2\n",
    "        if transition_tri.has_key(tuple(temp)):\n",
    "            transition_tri[tuple(temp)]+=1\n",
    "        else:\n",
    "            transition_tri[tuple(temp)]=1\n",
    "\n",
    "\n",
    "            \n",
    "# MAKING DICT {(TAG,TAG) : COUNT}\n",
    "\n",
    "\n",
    "for i in train_lab:\n",
    "    for each in window(i,2):\n",
    "        temp=list(each)\n",
    "        temp2=[]\n",
    "        temp2.append(temp[0][1])\n",
    "        temp2.append(temp[1][1])\n",
    "        temp=temp2\n",
    "        if transition_bi.has_key(tuple(temp)):\n",
    "            transition_bi[tuple(temp)]+=1\n",
    "        else:\n",
    "            transition_bi[tuple(temp)]=1\n",
    "            \n",
    "\n",
    "            \n",
    "# MAKING CONTEXT {(TAG) : COUNT}\n",
    "\n",
    "\n",
    "for i in train_lab:\n",
    "    for each in window(i,1):\n",
    "        temp=list(each)\n",
    "        temp2=[]\n",
    "        temp2.append(temp[0][1])\n",
    "        temp=temp2\n",
    "        if context.has_key(tuple(temp)):\n",
    "            context[tuple(temp)]+=1\n",
    "        else:\n",
    "            context[tuple(temp)]=1\n",
    "\n",
    "\n",
    "# MAKING EMISSION { TAG : WORD }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print context.items()[0:100]\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
